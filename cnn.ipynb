{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# cnn ç¥ç»ç½‘ç»œå®ç°\n",
    "ä¸ä½¿ç”¨pytorch å®ç°cnn\n",
    "éœ€è¦åœ¨ backward çš„åŸºç¡€ä¹‹ä¸Š åŠ ä¸Š å·ç§¯å±‚ã€æ± åŒ–å±‚çš„å®ç°å°±å¥½"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88695090c2ced300"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## å·ç§¯å±‚\n",
    "å·ç§¯å±‚æœ‰ä¸¤ä¸ªä¸œè¥¿ï¼Œä¸€ä¸ªæ˜¯data ä¸€ä¸ªæ˜¯filter(kernel),æ•´ä¸ªæµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤º\n",
    "<img src=\"å·ç§¯è¿ç®—.jpg\" height=960>\n",
    "\n",
    "### å¡«å……padding\n",
    "ä½¿ç”¨å¡«å……ä¸»è¦æ˜¯ä¸ºäº†è°ƒæ•´è¾“å‡ºçš„å¤§å°ã€‚æ¯”å¦‚,å¯¹å¤§å°ä¸º (4, 4) çš„è¾“å…¥  æ•°æ®åº”ç”¨ (3, 3) çš„æ»¤æ³¢å™¨æ—¶,è¾“å‡ºå¤§å°å˜ä¸º (2, 2),ç›¸å½“äºè¾“å‡ºå¤§å°  æ¯”è¾“å…¥å¤§å°ç¼©å°äº† 2 ä¸ªå…ƒç´ ã€‚è¿™åœ¨åå¤è¿›è¡Œå¤šæ¬¡å·ç§¯è¿ç®—çš„æ·±åº¦ç½‘  ç»œä¸­ä¼šæˆä¸ºé—®é¢˜ã€‚ä¸ºä»€ä¹ˆå‘¢?å› ä¸ºå¦‚æœæ¯æ¬¡è¿›è¡Œå·ç§¯è¿ç®—éƒ½ä¼šç¼©å°  ç©ºé—´,é‚£ä¹ˆåœ¨æŸä¸ªæ—¶åˆ»è¾“å‡ºå¤§å°å°±æœ‰å¯èƒ½å˜ä¸º 1,å¯¼è‡´æ— æ³•å†åº”ç”¨  å·ç§¯è¿ç®—ã€‚ä¸ºäº†é¿å…å‡ºç°è¿™æ ·çš„æƒ…å†µ,å°±è¦ä½¿ç”¨å¡«å……ã€‚åœ¨åˆšæ‰çš„ä¾‹  å­ä¸­,å°†å¡«å……çš„å¹…åº¦è®¾ä¸º 1,é‚£ä¹ˆç›¸å¯¹äºè¾“å…¥å¤§å° (4, 4),è¾“å‡ºå¤§å°  ä¹Ÿä¿æŒä¸ºåŸæ¥çš„ (4, 4)ã€‚å› æ­¤,å·ç§¯è¿ç®—å°±å¯ä»¥åœ¨ä¿æŒç©ºé—´å¤§å°ä¸å˜  çš„æƒ…å†µä¸‹å°†æ•°æ®ä¼ ç»™ä¸‹ä¸€å±‚ã€‚\n",
    "\n",
    "### channel\n",
    "å½“å›¾ç‰‡ä¸æ˜¯ç°è‰²ï¼Œè€Œæ˜¯rgb 3é€šé“çš„æ•°æ®æ—¶ï¼Œfilter ä¹Ÿåº”è¯¥æ˜¯3é€šé“çš„ï¼Œè¿™æ ·å·ç§¯å‡ºæ¥çš„ä¼šåç¼©æˆäºŒç»´æ•°æ®,å¦‚å›¾æ‰€ç¤ºã€‚\n",
    "<br>\n",
    "<img src=\"n_channel.jpg\">\n",
    "<br>\n",
    "å¦‚æœä½ æƒ³å·ç§¯åçš„é€šé“æ•°å’Œå·ç§¯å‰çš„ä¸€æ ·ï¼Œé‚£ä¹ˆåº”è¯¥ä½¿ç”¨å¤šä¸ªfilterï¼Œå¹¶ä¸”æ¯ä¸ªfilteréƒ½æ˜¯å’Œå›¾ç‰‡ç›¸åŒçš„é€šé“æ•°ï¼Œå¦‚å›¾æ‰€ç¤º\n",
    "<br>\n",
    "<img src=\"n_filter.jpg\">"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db7d837e95deadd8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## æ± åŒ–å±‚\n",
    "æ± åŒ–æ˜¯ç¼©å°é«˜ã€é•¿æ–¹å‘ä¸Šçš„ç©ºé—´çš„è¿ç®—\n",
    "<br>\n",
    "<img src=\"max_pool.jpg\">\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7005236327cc1add"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## im2col and col2im\n",
    "å·ç§¯å±‚å’Œæ± åŒ–å±‚çš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­éœ€è¦ç”¨åˆ°çš„ä¸¤ä¸ªæ–¹æ³•ï¼Œç”¨äºç®€åŒ–è®¡ç®—\n",
    "åŸç†ï¼šim2col æ˜¯æŠŠ 3ç»´å›¾åƒæŒ‰ç…§æ¯ä¸ªå·ç§¯æ ¸çš„å¤§å°ï¼Œæ¯ä¸€ä¸ªéƒ½å±•å¼€æˆä¸€ä¸ªcol,å†æŠŠæ¯ä¸ª3é€šé“çš„filter å±•å¼€æˆä¸€åˆ—ã€‚ç„¶åå·ç§¯å°±æˆä¸ºäº†çŸ©é˜µä¹˜æ³•\n",
    "ä¸€ä¸ª3é€šé“å›¾åƒä¼šå˜æˆä¸€ä¸ªäºŒç»´çŸ©é˜µï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯éœ€è¦è¿›è¡Œå·ç§¯è¿ç®—çš„å€¼ï¼Œç„¶å3é€šé“çš„filterä¹Ÿå˜æˆäº†ä¸€ä¸ªäºŒç»´çŸ©é˜µï¼Œæ¯ä¸€åˆ—éƒ½æ˜¯ä¸€ä¸ªfilterã€‚è¿™ä¸¤ä¸ªçŸ©é˜µè¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œç„¶åéœ€è¦æŠŠå¾—åˆ°çš„æ–°çŸ©é˜µåšreshape->æ–°çŸ©é˜µçš„æ¯ä¸€åˆ—éƒ½æ˜¯ä¸€æ¬¡å·ç§¯çš„ç»“æœï¼Œéƒ½åº”è¯¥reshapeæˆä¸€ä¸ªOHxOWçš„çŸ©é˜µï¼Œç„¶åå¦‚æœæ˜¯æœ‰fnä¸ªfilterçš„ï¼Œæ–°çš„çŸ©é˜µåº”è¯¥ä¼šæœ‰fnåˆ—ï¼Œå°±è¦reshapeæˆfnxOHxOW\n",
    "<br>\n",
    "<img src=\"img/im2col.jpg\">\n",
    "<br>\n",
    "\n",
    "<img src=\"img/im2col_all.jpg\">"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a373fd4395a9ce2d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os, time, random\n",
    "from typing import List, Tuple\n",
    "from PIL import Image, ImageOps,ImageEnhance, ImageChops, ImageFilter\n",
    "from tqdm import tqdm\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-20T06:02:59.400365Z",
     "start_time": "2025-11-20T06:02:59.301757Z"
    }
   },
   "id": "6e1abe275ed02cab",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def softmax(z: np.ndarray) -> np.ndarray:\n",
    "    z = z - z.max(axis=1, keepdims=True)\n",
    "    ez = np.exp(z, dtype=np.float32)\n",
    "    return ez / (np.sum(ez, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "def cross_entropy_loss(probs: np.ndarray, y_true_idx: np.ndarray):\n",
    "    \"\"\"\n",
    "    probs: (N, C) after softmax\n",
    "    y_true_idx: (N,) integer labels\n",
    "    returns (loss, grad_logits)\n",
    "    \"\"\"\n",
    "    N = probs.shape[0]\n",
    "    logp = -np.log(probs[np.arange(N), y_true_idx] + 1e-12)\n",
    "    loss = float(np.mean(logp))\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-20T06:02:59.404397Z",
     "start_time": "2025-11-20T06:02:59.401530Z"
    }
   },
   "id": "73fc95f46df149b2",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Adam:\n",
    "\n",
    "    \"\"\"Adam (http://arxiv.org/abs/1412.6980v8)\"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = {}, {}\n",
    "            for key, val in params.items():\n",
    "                self.m[key] = np.zeros_like(val)\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         \n",
    "        \n",
    "        for key in params.keys():\n",
    "            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n",
    "            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])\n",
    "            \n",
    "            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-20T06:02:59.412496Z",
     "start_time": "2025-11-20T06:02:59.404950Z"
    }
   },
   "id": "972a342732a5f591",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def augment_pil(img, img_size):\n",
    "    # éšæœºæ°´å¹³/å‚ç›´ç¿»è½¬\n",
    "    if random.random() < 0.5:\n",
    "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    if random.random() < 0.3:\n",
    "        img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "    # éšæœºæ—‹è½¬ Â±15Â°\n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        img = img.rotate(angle, resample=Image.BILINEAR, fillcolor=0)\n",
    "\n",
    "    # éšæœºå¹³ç§»ï¼ˆæ¨¡æ‹Ÿä½ç½®åç§»ï¼‰\n",
    "    if random.random() < 0.6:\n",
    "        w, h = img.size\n",
    "        max_dx = int(0.1 * w)\n",
    "        max_dy = int(0.1 * h)\n",
    "        dx = random.randint(-max_dx, max_dx)\n",
    "        dy = random.randint(-max_dy, max_dy)\n",
    "        img = ImageChops.offset(img, dx, dy)\n",
    "        img = img.crop((max_dx, max_dy, w-max_dx, h-max_dy))  # crop back\n",
    "        img = img.resize((img_size, img_size), Image.BILINEAR)\n",
    "\n",
    "    # éšæœºäº®åº¦/å¯¹æ¯”åº¦\n",
    "    if random.random() < 0.6:\n",
    "        factor = random.uniform(0.7, 1.4)\n",
    "        img = ImageEnhance.Brightness(img).enhance(factor)\n",
    "    if random.random() < 0.6:\n",
    "        factor = random.uniform(0.7, 1.4)\n",
    "        img = ImageEnhance.Contrast(img).enhance(factor)\n",
    "\n",
    "    # è½»å¾®é«˜æ–¯æ¨¡ç³Šï¼ˆé˜²é”åŒ–è¿‡æ‹Ÿåˆï¼‰\n",
    "    if random.random() < 0.2:\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.3, 0.8)))\n",
    "\n",
    "    # éšæœºæ“¦é™¤ï¼ˆCoarseDropout æ¨¡æ‹Ÿï¼‰\n",
    "    if random.random() < 0.3:\n",
    "        arr = np.array(img)\n",
    "        h, w = arr.shape\n",
    "        for _ in range(random.randint(1, 6)):\n",
    "            x = random.randint(0, w-4)\n",
    "            y = random.randint(0, h-4)\n",
    "            arr[y:y+random.randint(1,4), x:x+random.randint(1,4)] = 0\n",
    "        img = Image.fromarray(arr)\n",
    "\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-20T06:02:59.420612Z",
     "start_time": "2025-11-20T06:02:59.415822Z"
    }
   },
   "id": "d1546991b1e37cb6",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def im2col(input_data, kernel_h, kernel_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "    å°†è¾“å…¥è½¬æ¢ä¸ºåˆ—çŸ©é˜µï¼Œæ¯ä¸ª filter å¤§å°çš„å—å±•å¹³ä¸ºä¸€è¡Œã€‚\n",
    "    \n",
    "    input_data: shape (N, C, H, W)\n",
    "    è¿”å›: shape (N * out_h * out_w, C * kernel_h * kernel_w)\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "\n",
    "    out_h = (H + 2 * pad - kernel_h) // stride + 1\n",
    "    out_w = (W + 2 * pad - kernel_w) // stride + 1\n",
    "\n",
    "    # å¡«å……\n",
    "    img = np.pad(input_data, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "\n",
    "    # åˆå§‹åŒ– col çŸ©é˜µ\n",
    "    col = np.zeros((N, C, kernel_h, kernel_w, out_h, out_w))\n",
    "\n",
    "    # åˆ©ç”¨æ­¥è¿›æå–æ¯ä¸ªçª—å£\n",
    "    # è¿™ä¸€æ­¥å¾ˆæœ‰è¶£ï¼Œè™½ç„¶è¯´æ˜¯æ¯ä¸€æ¬¡æŠŠfilterå¯¹åº”çš„img data é“ºå¹³æˆä¸€è¡Œï¼Œä½†æ˜¯è¿™è¾¹ä¸æ˜¯è¿™æ ·åšçš„\n",
    "    for i in range(kernel_h):\n",
    "        i_max = i + stride * out_h\n",
    "        for j in range(kernel_w):\n",
    "            j_max = j + stride * out_w\n",
    "            col[:, :, i, j, :, :] = img[:, :, i:i_max:stride, j:j_max:stride]\n",
    "        \n",
    "\n",
    "    # è½¬ç½® + reshapeï¼šæŠŠ (N, out_h, out_w, C, K_h, K_w) -> (N*out_h*out_w, C*K_h*K_w)\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)\n",
    "    return col\n",
    "\n",
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    col :\n",
    "    input_shape : è¾“å…¥æ•°æ®çš„å½¢çŠ¶ï¼ˆä¾‹ï¼š(10, 1, 28, 28)ï¼‰\n",
    "    filter_h :\n",
    "    filter_w\n",
    "    stride\n",
    "    pad\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-20T06:02:59.427008Z",
     "start_time": "2025-11-20T06:02:59.421458Z"
    }
   },
   "id": "ad50e73ec2a61f26",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, K, b, stride = 1, pad = 0):\n",
    "        self.K = K\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # ä¸­é—´æ•°æ®ï¼ˆbackwardæ—¶ä½¿ç”¨ï¼‰\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_K = None\n",
    "        \n",
    "        # æƒé‡å’Œåç½®å‚æ•°çš„æ¢¯åº¦\n",
    "        self.dK = None\n",
    "        self.db = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        fn, c, kh, kw = self.K.shape\n",
    "        N,C,H,W = x.shape\n",
    "        out_h = (H + 2* self.pad -kh)//self.stride + 1\n",
    "        out_w = (W + 2* self.pad -kw)//self.stride + 1\n",
    "        col = im2col(x,kh, kw, self.stride, self.pad)\n",
    "        col_K = self.K.reshape(fn, -1).T\n",
    "        out = col@col_K + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_K = col_K\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        FN, C, FH, FW = self.K.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dK = np.dot(self.col.T, dout)\n",
    "        self.dK = self.dK.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = dout @ self.col_K.T\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-20T06:02:59.434696Z",
     "start_time": "2025-11-20T06:02:59.427954Z"
    }
   },
   "id": "cf0c727f13707610",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-20T06:02:59.440697Z",
     "start_time": "2025-11-20T06:02:59.435336Z"
    }
   },
   "id": "11457bf67747b870",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class simpleConvNet:\n",
    "    # conv -> relu -> pool ->conv->relu->pool->full->relu->full\n",
    "    #conv_param = {'filter_nums': [8,16], 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "        def __init__(self, img_size, f1: int =8 ,f2: int =16,k1: int =5 ,k2: int =5,stride: int = 1, pad: int = 0,\n",
    "                 hidden_size=64, num_classes=5, weight_init_std=0.01):\n",
    "            self.img_size = img_size\n",
    "            self.input_dim = [1, img_size, img_size]\n",
    "            self.filter_nums = [f1, f2]\n",
    "            self.filter_size = k1\n",
    "            self.filter_pad = pad\n",
    "            self.filter_stride = pad\n",
    "    \n",
    "            # åˆå§‹åŒ–æƒé‡\n",
    "            self.params = {}\n",
    "            self.params['K1'] = np.random.randn(self.filter_nums[0], self.input_dim[0], self.filter_size, self.filter_size).astype(np.float32) * np.sqrt(2.0 / (self.filter_size * self.filter_size * self.input_dim[0]))\n",
    "            \n",
    "            self.params['b1'] = np.zeros(self.filter_nums[0])\n",
    "            self.params['K2'] = np.random.randn(self.filter_nums[1], self.filter_nums[0], self.filter_size, self.filter_size).astype(np.float32) * np.sqrt(2.0 / (self.filter_size * self.filter_size * self.filter_nums[0]))\n",
    "            self.params['b2'] = np.zeros(self.filter_nums[1])\n",
    "            \n",
    "            s1 = self.img_size - self.filter_size + 1\n",
    "            s1p = s1 // 2\n",
    "            s2 = s1p - self.filter_size + 1\n",
    "            s2p = s2 // 2\n",
    "            self.flat_dim = s2p * s2p * self.filter_nums[1]\n",
    "            \n",
    "            self.params['W1'] = np.random.randn(self.flat_dim, hidden_size).astype(np.float32) * np.sqrt(2.0 / self.flat_dim)\n",
    "            self.params['b3'] = np.zeros((hidden_size,), dtype=np.float32)\n",
    "            self.params['W2'] = np.random.randn(hidden_size, num_classes).astype(np.float32) * np.sqrt(2.0 / hidden_size)\n",
    "            self.params['b4'] = np.zeros((num_classes,), dtype=np.float32)\n",
    "    \n",
    "            # ç”Ÿæˆå±‚\n",
    "            self.layers = OrderedDict()\n",
    "            self.layers['Conv1'] = Convolution(self.params['K1'], self.params['b1'],\n",
    "                                               self.filter_stride, self.filter_pad)\n",
    "            self.layers['Relu1'] = Relu()\n",
    "            self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "            self.layers['Conv2'] = Convolution(self.params['K2'], self.params['b2'], self.filter_stride, self.filter_pad)\n",
    "            self.layers['Relu2'] = Relu()\n",
    "            self.layers['Pool2'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "            self.layers['Affine1'] = Affine(self.params['W1'], self.params['b3'])\n",
    "            self.layers['Relu3'] = Relu()\n",
    "            self.layers['Affine2'] = Affine(self.params['W2'], self.params['b4'])\n",
    "    \n",
    "            self.last_layer = SoftmaxWithLoss()\n",
    "    \n",
    "        def predict(self, x):\n",
    "            for layer in self.layers.values():\n",
    "                x = layer.forward(x)\n",
    "    \n",
    "            return x\n",
    "    \n",
    "        def loss(self, x, t):\n",
    "            \"\"\"æ±‚æŸå¤±å‡½æ•°\n",
    "            \"\"\"\n",
    "            y = self.predict(x)\n",
    "            return y, self.last_layer.forward(y, t)\n",
    "    \n",
    "        def accuracy(self, x, t, batch_size=100):\n",
    "            if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "            \n",
    "            acc = 0.0\n",
    "            \n",
    "            for i in range(int(x.shape[0] / batch_size)):\n",
    "                tx = x[i*batch_size:(i+1)*batch_size]\n",
    "                tt = t[i*batch_size:(i+1)*batch_size]\n",
    "                y = self.predict(tx)\n",
    "                y = np.argmax(y, axis=1)\n",
    "                acc += np.sum(y == tt) \n",
    "            \n",
    "            return acc / x.shape[0]\n",
    "    \n",
    "        def gradient(self, x, t):\n",
    "            \"\"\"æ±‚æ¢¯åº¦ï¼ˆè¯¯å·®åå‘ä¼ æ’­æ³•ï¼‰\n",
    "    \n",
    "            Parameters\n",
    "            ----------\n",
    "            x : è¾“å…¥æ•°æ®\n",
    "            t : æ•™å¸ˆæ ‡ç­¾\n",
    "    \n",
    "            Returns\n",
    "            -------\n",
    "            å…·æœ‰å„å±‚çš„æ¢¯åº¦çš„å­—å…¸å˜é‡\n",
    "                grads['W1']ã€grads['W2']ã€...æ˜¯å„å±‚çš„æƒé‡\n",
    "                grads['b1']ã€grads['b2']ã€...æ˜¯å„å±‚çš„åç½®\n",
    "            \"\"\"\n",
    "    \n",
    "            # backward\n",
    "            dout = 1\n",
    "            dout = self.last_layer.backward(dout)\n",
    "    \n",
    "            layers = list(self.layers.values())\n",
    "            layers.reverse()\n",
    "            for layer in layers:\n",
    "                dout = layer.backward(dout)\n",
    "    \n",
    "            # è®¾å®š\n",
    "            grads = {}\n",
    "            grads['K1'], grads['b1'] = self.layers['Conv1'].dK, self.layers['Conv1'].db\n",
    "            grads['K2'], grads['b2'] = self.layers['Conv2'].dK, self.layers['Conv2'].db\n",
    "            grads['W1'], grads['b3'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "            grads['W2'], grads['b4'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "    \n",
    "            return grads\n",
    "            \n",
    "        def save_params(self, file_name=\"params.pkl\"):\n",
    "            params = {}\n",
    "            for key, val in self.params.items():\n",
    "                params[key] = val\n",
    "            with open(file_name, 'wb') as f:\n",
    "                pickle.dump(params, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-20T06:02:59.451087Z",
     "start_time": "2025-11-20T06:02:59.441574Z"
    }
   },
   "id": "57d196651ae27e11",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W =W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # æƒé‡å’Œåç½®å‚æ•°çš„å¯¼æ•°\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # å¯¹åº”å¼ é‡\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # è¿˜åŸè¾“å…¥æ•°æ®çš„å½¢çŠ¶ï¼ˆå¯¹åº”å¼ é‡ï¼‰\n",
    "        return dx\n",
    "    \n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None # softmaxçš„è¾“å‡º\n",
    "        self.t = None # ç›‘ç£æ•°æ®\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss= cross_entropy_loss(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # ç›‘ç£æ•°æ®æ˜¯one-hot-vectorçš„æƒ…å†µ\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \n",
    "        return dx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-20T06:02:59.458556Z",
     "start_time": "2025-11-20T06:02:59.451725Z"
    }
   },
   "id": "39b77e4e1ffb39df",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ä¸€äº›å·¥å…·\n",
    "# === Simple dataset loader for folder structure ===\n",
    "IMG_SIZE = 100\n",
    "\n",
    "def accuracy(logits, y):\n",
    "    preds = np.argmax(softmax(logits), axis=1)\n",
    "    return float(np.mean(preds == y))\n",
    "\n",
    "def list_images(root: str) -> Tuple[list, list]:\n",
    "    classes = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))])\n",
    "    items = []\n",
    "    for ci, cname in enumerate(classes):\n",
    "        cdir = os.path.join(root, cname)\n",
    "        for fn in os.listdir(cdir):\n",
    "            if fn.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                items.append((os.path.join(cdir, fn), ci))\n",
    "    return items, classes\n",
    "\n",
    "def load_batch(paths_labels, start, end, img_size=IMG_SIZE, augment=False):\n",
    "    batch = paths_labels[start:end]\n",
    "    N = len(batch)\n",
    "    X = np.zeros((N, 1,img_size, img_size), dtype=np.float32)\n",
    "    y = np.zeros((N,), dtype=np.int64)\n",
    "    for i, (p, lab) in enumerate(batch):\n",
    "        img = Image.open(p).convert('L')  # grayscale\n",
    "        # if augment:\n",
    "        #    # img = augment_pil(img, img_size)\n",
    "        #     # 1. æ°´å¹³ç¿»è½¬\n",
    "        #     if random.random() < 0.5:\n",
    "        #         img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        # \n",
    "        #     # 2. æ—‹è½¬ (-15Â° ~ +15Â°)\n",
    "        #     if random.random() < 0.4:\n",
    "        #         angle = random.uniform(-15, 15)\n",
    "        #         img = img.rotate(angle, resample=Image.BILINEAR, fillcolor=0)\n",
    "        # \n",
    "        #     # 3. ç¼©æ”¾ (0.9x ~ 1.1x)\n",
    "        #     if random.random() < 0.4:\n",
    "        #         scale = random.uniform(0.9, 1.1)\n",
    "        #         w, h = img.size\n",
    "        #         new_w, new_h = int(w * scale), int(h * scale)\n",
    "        #         img = img.resize((new_w, new_h), Image.BILINEAR)\n",
    "        #         # è£å‰ªæˆ–å¡«å……å›åŸå°ºå¯¸ï¼ˆè¿™é‡Œç”¨ center crop + padï¼‰\n",
    "        #         if scale > 1.0:\n",
    "        #             # zoom in: center crop\n",
    "        #             left = (new_w - w) // 2\n",
    "        #             top = (new_h - h) // 2\n",
    "        #             img = img.crop((left, top, left + w, top + h))\n",
    "        #         else:\n",
    "        #             # zoom out: pad with black\n",
    "        #             img = ImageOps.pad(img, (w, h), color=0, centering=(0.5, 0.5))\n",
    "        # \n",
    "        #     # 4. å¹³ç§» (-10% ~ +10% of size)\n",
    "        #     if random.random() < 0.4:\n",
    "        #         w, h = img.size\n",
    "        #         tx = random.uniform(-0.1, 0.1) * w\n",
    "        #         ty = random.uniform(-0.1, 0.1) * h\n",
    "        #         img = img.transform(\n",
    "        #             (w, h),\n",
    "        #             Image.AFFINE,\n",
    "        #             (1, 0, tx, 0, 1, ty),\n",
    "        #             resample=Image.BILINEAR,\n",
    "        #             fillcolor=0\n",
    "        #         )\n",
    "        # \n",
    "        #     # 5. å‰ªåˆ‡ (shear, -10Â° ~ +10Â°)\n",
    "        #     if random.random() < 0.3:\n",
    "        #         shear_angle = random.uniform(-10, 10)  # degrees\n",
    "        #         shear_factor = np.tan(np.radians(shear_angle))\n",
    "        #         w, h = img.size\n",
    "        #         img = img.transform(\n",
    "        #             (w, h),\n",
    "        #             Image.AFFINE,\n",
    "        #             (1, shear_factor, 0, 0, 1, 0),\n",
    "        #             resample=Image.BILINEAR,\n",
    "        #             fillcolor=0\n",
    "        #         )\n",
    "        if augment:\n",
    "            # basic augmentation examples\n",
    "            if random.random() < 0.5:\n",
    "                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            if random.random() < 0.3:\n",
    "                angle = random.uniform(-10, 10)\n",
    "                img = img.rotate(angle, resample=Image.BILINEAR, fillcolor=0)\n",
    "                \n",
    "        img = img.resize((img_size, img_size), Image.BILINEAR)\n",
    "        X[i] = np.expand_dims(np.asarray(img, dtype=np.float32) / 255.0, axis=0)\n",
    "        y[i] = lab\n",
    "    return X, y\n",
    "\n",
    "def state_dict(model):\n",
    "    \"\"\"\n",
    "    Collect all top-level numpy array attributes from the model.\n",
    "    Returns a dict: {name: np.ndarray}\n",
    "    \"\"\"\n",
    "    sd = {}\n",
    "    for name, val in vars(model).items():\n",
    "        if isinstance(val, np.ndarray):\n",
    "            sd[name] = val\n",
    "    return sd\n",
    "\n",
    "def load_state_dict(model, state, strict=True):\n",
    "    \"\"\"\n",
    "    Load arrays from `state` (a dict of name->ndarray) into model attributes.\n",
    "    If strict=True, raises on missing keys or shape mismatch.\n",
    "    Returns a report dict.\n",
    "    \"\"\"\n",
    "    report = {\"loaded\": [], \"missing_in_model\": [], \"missing_in_state\": [], \"shape_mismatch\": []}\n",
    "    model_vars = vars(model)\n",
    "    # apply\n",
    "    for k, arr in state.items():\n",
    "        if k not in model_vars:\n",
    "            report[\"missing_in_model\"].append(k)\n",
    "            if strict:\n",
    "                raise KeyError(f\"Parameter '{k}' not found in model.\")\n",
    "            continue\n",
    "        if not isinstance(model_vars[k], np.ndarray):\n",
    "            report[\"shape_mismatch\"].append((k, \"not an ndarray on model\"))\n",
    "            if strict:\n",
    "                raise TypeError(f\"Model attribute '{k}' is not an ndarray.\")\n",
    "            continue\n",
    "        if model_vars[k].shape != arr.shape:\n",
    "            report[\"shape_mismatch\"].append((k, (model_vars[k].shape, arr.shape)))\n",
    "            if strict:\n",
    "                raise ValueError(f\"Shape mismatch for '{k}': model {model_vars[k].shape} vs state {arr.shape}\")\n",
    "            # non-strict: still load\n",
    "        setattr(model, k, arr.astype(model_vars[k].dtype, copy=True))\n",
    "        report[\"loaded\"].append(k)\n",
    "    # find params that were expected but not provided\n",
    "    for k, v in model_vars.items():\n",
    "        if isinstance(v, np.ndarray) and k not in state:\n",
    "            report[\"missing_in_state\"].append(k)\n",
    "    return report\n",
    "\n",
    "def save_model(model, classes, path=\"checkpoints/model_final.npz\", extra_meta=None):\n",
    "    \"\"\"\n",
    "    Save model parameters (all top-level ndarrays) and metadata into a .npz file.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    sd = state_dict(model)\n",
    "    meta = {\n",
    "        \"model_class\": model.__class__.__name__,\n",
    "        \"img_size\": getattr(model, \"img_size\", None),\n",
    "        \"num_classes\": getattr(model, \"num_classes\", None),\n",
    "        \"lr\": getattr(model, \"lr\", None),\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"classes\": classes,\n",
    "    }\n",
    "    if extra_meta:\n",
    "        meta.update(extra_meta)\n",
    "    # pack: all arrays under their own keys + one 'meta' json\n",
    "    np.savez(path, **sd, meta=np.array([json.dumps(meta)], dtype=object))\n",
    "    print(f\"ğŸ’¾ Saved {len(sd)} tensors to {path}\")\n",
    "    return {\"num_tensors\": len(sd), \"path\": path, \"meta\": meta}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-20T06:02:59.491504Z",
     "start_time": "2025-11-20T06:02:59.483310Z"
    }
   },
   "id": "887dab96f58b915f",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['bird', 'car', 'cat', 'dog', 'person'] (num_classes=5)\n",
      "\n",
      "=== Epoch 1/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.71it/s, acc=28.6%, loss=1.612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Train: loss=1.6747, acc=0.216, time=5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 16.25it/s, acc=0.0%, loss=1.658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Val  : loss=1.5994, acc=0.284, time=1.0s\n",
      "\n",
      "=== Epoch 2/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  9.02it/s, acc=35.7%, loss=1.534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 Train: loss=1.6011, acc=0.251, time=5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 16.91it/s, acc=0.0%, loss=1.635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 Val  : loss=1.5954, acc=0.204, time=0.9s\n",
      "\n",
      "=== Epoch 3/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.74it/s, acc=35.7%, loss=1.566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 Train: loss=1.5782, acc=0.291, time=5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 17.70it/s, acc=30.0%, loss=1.538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 Val  : loss=1.5475, acc=0.344, time=0.9s\n",
      "\n",
      "=== Epoch 4/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  9.27it/s, acc=35.7%, loss=1.574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 Train: loss=1.5398, acc=0.337, time=5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 14.92it/s, acc=30.0%, loss=1.413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 Val  : loss=1.4879, acc=0.356, time=1.1s\n",
      "\n",
      "=== Epoch 5/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.96it/s, acc=14.3%, loss=1.635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 Train: loss=1.5338, acc=0.320, time=5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 17.29it/s, acc=30.0%, loss=1.567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 Val  : loss=1.5145, acc=0.400, time=0.9s\n",
      "\n",
      "=== Epoch 6/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.95it/s, acc=35.7%, loss=1.430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 Train: loss=1.4753, acc=0.385, time=5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 16.97it/s, acc=70.0%, loss=1.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 Val  : loss=1.4291, acc=0.412, time=0.9s\n",
      "\n",
      "=== Epoch 7/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.77it/s, acc=71.4%, loss=1.181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 Train: loss=1.4022, acc=0.409, time=5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 18.19it/s, acc=80.0%, loss=1.064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 Val  : loss=1.4713, acc=0.380, time=0.9s\n",
      "\n",
      "=== Epoch 8/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  9.17it/s, acc=57.1%, loss=1.206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 Train: loss=1.3179, acc=0.473, time=5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 16.48it/s, acc=60.0%, loss=1.058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 Val  : loss=1.1901, acc=0.532, time=1.0s\n",
      "\n",
      "=== Epoch 9/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.18it/s, acc=28.6%, loss=1.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 Train: loss=1.2478, acc=0.501, time=5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 15.81it/s, acc=70.0%, loss=0.837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 Val  : loss=1.2568, acc=0.472, time=1.0s\n",
      "\n",
      "=== Epoch 10/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  9.00it/s, acc=42.9%, loss=1.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train: loss=1.1533, acc=0.548, time=5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 17.59it/s, acc=60.0%, loss=0.975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Val  : loss=1.1410, acc=0.560, time=0.9s\n",
      "\n",
      "=== Epoch 11/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  9.01it/s, acc=64.3%, loss=0.919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Train: loss=1.0180, acc=0.583, time=5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 15.86it/s, acc=50.0%, loss=0.892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Val  : loss=0.8932, acc=0.676, time=1.0s\n",
      "\n",
      "=== Epoch 12/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  9.08it/s, acc=85.7%, loss=0.708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Train: loss=0.9384, acc=0.649, time=5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 17.36it/s, acc=60.0%, loss=1.249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Val  : loss=0.8688, acc=0.656, time=0.9s\n",
      "\n",
      "=== Epoch 13/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  9.16it/s, acc=92.9%, loss=0.500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Train: loss=0.9298, acc=0.655, time=5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 16.83it/s, acc=80.0%, loss=0.640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Val  : loss=0.7651, acc=0.720, time=1.0s\n",
      "\n",
      "=== Epoch 14/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.89it/s, acc=71.4%, loss=0.851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Train: loss=0.8097, acc=0.699, time=5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 15.15it/s, acc=90.0%, loss=0.420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Val  : loss=0.6135, acc=0.796, time=1.1s\n",
      "\n",
      "=== Epoch 15/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  9.05it/s, acc=78.6%, loss=0.533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Train: loss=0.7034, acc=0.759, time=5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 18.01it/s, acc=80.0%, loss=0.447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Val  : loss=0.5177, acc=0.828, time=0.9s\n",
      "\n",
      "=== Epoch 16/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  9.07it/s, acc=92.9%, loss=0.471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Train: loss=0.6135, acc=0.797, time=5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 15.96it/s, acc=100.0%, loss=0.215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Val  : loss=0.4135, acc=0.888, time=1.0s\n",
      "\n",
      "=== Epoch 17/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.56it/s, acc=71.4%, loss=0.512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Train: loss=0.5161, acc=0.824, time=5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 14.28it/s, acc=100.0%, loss=0.203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Val  : loss=0.3933, acc=0.868, time=1.1s\n",
      "\n",
      "=== Epoch 18/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  9.19it/s, acc=92.9%, loss=0.574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Train: loss=0.5144, acc=0.809, time=5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 13.45it/s, acc=90.0%, loss=0.248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Val  : loss=0.3416, acc=0.924, time=1.2s\n",
      "\n",
      "=== Epoch 19/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:06<00:00,  7.34it/s, acc=100.0%, loss=0.163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Train: loss=0.5143, acc=0.837, time=6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 13.43it/s, acc=100.0%, loss=0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Val  : loss=0.2846, acc=0.924, time=1.2s\n",
      "\n",
      "=== Epoch 20/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:06<00:00,  7.25it/s, acc=85.7%, loss=0.376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Train: loss=0.3995, acc=0.873, time=6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 14.18it/s, acc=100.0%, loss=0.081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Val  : loss=0.2189, acc=0.948, time=1.1s\n",
      "\n",
      "=== Epoch 21/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.74it/s, acc=92.9%, loss=0.224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Train: loss=0.3399, acc=0.900, time=5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 17.64it/s, acc=100.0%, loss=0.025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Val  : loss=0.1729, acc=0.952, time=0.9s\n",
      "\n",
      "=== Epoch 22/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.68it/s, acc=100.0%, loss=0.138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Train: loss=0.3000, acc=0.909, time=5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 15.55it/s, acc=100.0%, loss=0.018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Val  : loss=0.1444, acc=0.960, time=1.0s\n",
      "\n",
      "=== Epoch 23/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.44it/s, acc=85.7%, loss=0.574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Train: loss=0.2578, acc=0.924, time=5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 17.42it/s, acc=100.0%, loss=0.106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Val  : loss=0.1851, acc=0.952, time=0.9s\n",
      "\n",
      "=== Epoch 24/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.69it/s, acc=100.0%, loss=0.192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Train: loss=0.2636, acc=0.935, time=5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 15.82it/s, acc=100.0%, loss=0.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Val  : loss=0.1672, acc=0.964, time=1.0s\n",
      "\n",
      "=== Epoch 25/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.56it/s, acc=57.1%, loss=1.213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Train: loss=0.3670, acc=0.884, time=5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 15.91it/s, acc=100.0%, loss=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Val  : loss=0.2236, acc=0.944, time=1.0s\n",
      "\n",
      "=== Epoch 26/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.71it/s, acc=92.9%, loss=0.224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Train: loss=0.2397, acc=0.920, time=5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 17.22it/s, acc=100.0%, loss=0.018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Val  : loss=0.1758, acc=0.956, time=0.9s\n",
      "\n",
      "=== Epoch 27/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.70it/s, acc=100.0%, loss=0.069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Train: loss=0.3118, acc=0.916, time=5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 16.12it/s, acc=100.0%, loss=0.018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Val  : loss=0.1500, acc=0.972, time=1.0s\n",
      "\n",
      "=== Epoch 28/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.68it/s, acc=100.0%, loss=0.033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Train: loss=0.2542, acc=0.931, time=5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 14.55it/s, acc=100.0%, loss=0.018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Val  : loss=0.1121, acc=0.984, time=1.1s\n",
      "\n",
      "=== Epoch 29/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.50it/s, acc=100.0%, loss=0.041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Train: loss=0.1577, acc=0.949, time=5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 16.94it/s, acc=100.0%, loss=0.010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Val  : loss=0.0891, acc=0.980, time=0.9s\n",
      "\n",
      "=== Epoch 30/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  9.11it/s, acc=92.9%, loss=0.137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Train: loss=0.1353, acc=0.964, time=5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 16.18it/s, acc=100.0%, loss=0.004]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Val  : loss=0.0767, acc=0.988, time=1.0s\n",
      "\n",
      "âœ… Training finished in 3.20 minutes.\n",
      "ğŸ”š Final losses â€” train: 0.1353, val: 0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train():\n",
    "    data_root = 'dataset'\n",
    "    epochs = 30\n",
    "    batch_size = 16\n",
    "    img_size = 100\n",
    "    use_augment = True\n",
    "    lr=0.0413\n",
    "    \n",
    "    t0_total = time.time()\n",
    "    \n",
    "    train_items, classes = list_images(os.path.join(data_root, 'train'))\n",
    "    val_items, _ = list_images(os.path.join(data_root, 'val'))\n",
    "    num_classes = len(classes)\n",
    "    print(f'Classes: {classes} (num_classes={num_classes})')\n",
    "    \n",
    "    network = simpleConvNet(img_size=IMG_SIZE, \n",
    "                        conv_param = {'filter_nums': [8,16], 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=64, num_classes=5, weight_init_std=0.01)\n",
    "    \n",
    "    last_train_loss, last_val_loss = None, None\n",
    "    \n",
    "    # ---- Prepare save path ----\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        print(f\"\\n=== Epoch {ep}/{epochs} ===\")\n",
    "        random.shuffle(train_items)\n",
    "\n",
    "        # ---- Train ----\n",
    "        t0 = time.time()\n",
    "        loss_accum, acc_accum, seen = 0.0, 0.0, 0\n",
    "        pbar = tqdm(range(0, len(train_items), batch_size), desc=f\"Train {ep}\", ncols=80)\n",
    "        for s in pbar:\n",
    "            X, y = load_batch(train_items, s, min(s+batch_size, len(train_items)), img_size, augment=use_augment)\n",
    "            logits,loss = network.loss(X, y)\n",
    "            \n",
    "            grads = network.gradient(X, y)\n",
    "            # adam = Adam(lr=lr)\n",
    "            # adam.update(network.params, grads = grads)\n",
    "            for key in network.params.keys():\n",
    "                network.params[key] -= lr * grads[key] \n",
    "                \n",
    "            \n",
    "            #loss, dlogits = cross_entropy_loss(probs, y)\n",
    "            #model.backward(dlogits, cache)\n",
    "\n",
    "            acc = accuracy(logits, y)\n",
    "            bsz = X.shape[0]\n",
    "            loss_accum += loss * bsz\n",
    "            acc_accum += acc * bsz\n",
    "            seen += bsz\n",
    "            pbar.set_postfix(loss=f\"{loss:.3f}\", acc=f\"{acc*100:.1f}%\")\n",
    "\n",
    "        last_train_loss = loss_accum / max(1, seen)\n",
    "        train_time = time.time() - t0\n",
    "        print(f\"Epoch {ep:02d} Train: loss={last_train_loss:.4f}, acc={acc_accum/seen:.3f}, time={train_time:.1f}s\")\n",
    "\n",
    "        # ---- Val ----\n",
    "        t1 = time.time()\n",
    "        val_loss, val_acc, vseen = 0.0, 0.0, 0\n",
    "        pbar_val = tqdm(range(0, len(val_items), batch_size), desc=f\"Val {ep}\", ncols=80)\n",
    "        for s in pbar_val:\n",
    "            Xv, yv = load_batch(val_items, s, min(s+batch_size, len(val_items)), img_size, augment=False)\n",
    "            # logits, _ = model.forward(Xv)\n",
    "            # probs = softmax(logits)\n",
    "            # l, _ = cross_entropy_loss(probs, yv)\n",
    "            \n",
    "            logits, l = network.loss(Xv, yv)\n",
    "            a = accuracy(logits, yv)\n",
    "            bsz = Xv.shape[0]\n",
    "            val_loss += l * bsz\n",
    "            val_acc += a * bsz\n",
    "            vseen += bsz\n",
    "            pbar_val.set_postfix(loss=f\"{l:.3f}\", acc=f\"{a*100:.1f}%\")\n",
    "\n",
    "        last_val_loss = val_loss / max(1, vseen)\n",
    "        val_time = time.time() - t1\n",
    "        print(f\"Epoch {ep:02d} Val  : loss={last_val_loss:.4f}, acc={val_acc/vseen:.3f}, time={val_time:.1f}s\")\n",
    "\n",
    "    total_time = time.time() - t0_total\n",
    "    print(f\"\\nâœ… Training finished in {total_time/60:.2f} minutes.\")\n",
    "    print(f\"ğŸ”š Final losses â€” train: {last_train_loss:.4f}, val: {last_val_loss:.4f}\")\n",
    "    \n",
    "\n",
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-20T06:23:13.464814Z",
     "start_time": "2025-11-20T06:20:01.608898Z"
    }
   },
   "id": "7c47a00046c04b11",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c2be80d7e323cf",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
