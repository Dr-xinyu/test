{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# cnn 神经网络实现\n",
    "不使用pytorch 实现cnn\n",
    "需要在 backward 的基础之上 加上 卷积层、池化层的实现就好"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88695090c2ced300"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 卷积层\n",
    "卷积层有两个东西，一个是data 一个是filter(kernel),整个流程如下图所示\n",
    "<img src=\"卷积运算.jpg\" height=960>\n",
    "\n",
    "### 填充padding\n",
    "使用填充主要是为了调整输出的大小。比如,对大小为 (4, 4) 的输入  数据应用 (3, 3) 的滤波器时,输出大小变为 (2, 2),相当于输出大小  比输入大小缩小了 2 个元素。这在反复进行多次卷积运算的深度网  络中会成为问题。为什么呢?因为如果每次进行卷积运算都会缩小  空间,那么在某个时刻输出大小就有可能变为 1,导致无法再应用  卷积运算。为了避免出现这样的情况,就要使用填充。在刚才的例  子中,将填充的幅度设为 1,那么相对于输入大小 (4, 4),输出大小  也保持为原来的 (4, 4)。因此,卷积运算就可以在保持空间大小不变  的情况下将数据传给下一层。\n",
    "\n",
    "### channel\n",
    "当图片不是灰色，而是rgb 3通道的数据时，filter 也应该是3通道的，这样卷积出来的会坍缩成二维数据,如图所示。\n",
    "<br>\n",
    "<img src=\"n_channel.jpg\">\n",
    "<br>\n",
    "如果你想卷积后的通道数和卷积前的一样，那么应该使用多个filter，并且每个filter都是和图片相同的通道数，如图所示\n",
    "<br>\n",
    "<img src=\"n_filter.jpg\">"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db7d837e95deadd8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 池化层\n",
    "池化是缩小高、长方向上的空间的运算\n",
    "<br>\n",
    "<img src=\"max_pool.jpg\">\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7005236327cc1add"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## im2col and col2im\n",
    "卷积层和池化层的前向传播和后向传播需要用到的两个方法，用于简化计算\n",
    "原理：im2col 是把 3维图像按照每个卷积核的大小，每一个都展开成一个col,再把每个3通道的filter 展开成一列。然后卷积就成为了矩阵乘法\n",
    "一个3通道图像会变成一个二维矩阵，每一行都是需要进行卷积运算的值，然后3通道的filter也变成了一个二维矩阵，每一列都是一个filter。这两个矩阵进行矩阵乘法，然后需要把得到的新矩阵做reshape->新矩阵的每一列都是一次卷积的结果，都应该reshape成一个OHxOW的矩阵，然后如果是有fn个filter的，新的矩阵应该会有fn列，就要reshape成fnxOHxOW\n",
    "<br>\n",
    "<img src=\"img/im2col.jpg\">\n",
    "<br>\n",
    "\n",
    "<img src=\"img/im2col_all.jpg\">"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a373fd4395a9ce2d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os, time, random\n",
    "from typing import List, Tuple\n",
    "from PIL import Image, ImageOps,ImageEnhance, ImageChops, ImageFilter\n",
    "from tqdm import tqdm\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T18:12:39.550730Z",
     "start_time": "2025-11-06T18:12:39.546287Z"
    }
   },
   "id": "6e1abe275ed02cab",
   "execution_count": 182
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def softmax(z: np.ndarray) -> np.ndarray:\n",
    "    z = z - z.max(axis=1, keepdims=True)\n",
    "    ez = np.exp(z, dtype=np.float32)\n",
    "    return ez / (np.sum(ez, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "def cross_entropy_loss(probs: np.ndarray, y_true_idx: np.ndarray):\n",
    "    \"\"\"\n",
    "    probs: (N, C) after softmax\n",
    "    y_true_idx: (N,) integer labels\n",
    "    returns (loss, grad_logits)\n",
    "    \"\"\"\n",
    "    N = probs.shape[0]\n",
    "    logp = -np.log(probs[np.arange(N), y_true_idx] + 1e-12)\n",
    "    loss = float(np.mean(logp))\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T18:12:39.564530Z",
     "start_time": "2025-11-06T18:12:39.562160Z"
    }
   },
   "id": "73fc95f46df149b2",
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Adam:\n",
    "\n",
    "    \"\"\"Adam (http://arxiv.org/abs/1412.6980v8)\"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = {}, {}\n",
    "            for key, val in params.items():\n",
    "                self.m[key] = np.zeros_like(val)\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         \n",
    "        \n",
    "        for key in params.keys():\n",
    "            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n",
    "            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])\n",
    "            \n",
    "            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T18:12:39.570357Z",
     "start_time": "2025-11-06T18:12:39.567897Z"
    }
   },
   "id": "972a342732a5f591",
   "execution_count": 184
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def augment_pil(img, img_size):\n",
    "    # 随机水平/垂直翻转\n",
    "    if random.random() < 0.5:\n",
    "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    if random.random() < 0.3:\n",
    "        img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "    # 随机旋转 ±15°\n",
    "    if random.random() < 0.7:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        img = img.rotate(angle, resample=Image.BILINEAR, fillcolor=0)\n",
    "\n",
    "    # 随机平移（模拟位置偏移）\n",
    "    if random.random() < 0.6:\n",
    "        w, h = img.size\n",
    "        max_dx = int(0.1 * w)\n",
    "        max_dy = int(0.1 * h)\n",
    "        dx = random.randint(-max_dx, max_dx)\n",
    "        dy = random.randint(-max_dy, max_dy)\n",
    "        img = ImageChops.offset(img, dx, dy)\n",
    "        img = img.crop((max_dx, max_dy, w-max_dx, h-max_dy))  # crop back\n",
    "        img = img.resize((img_size, img_size), Image.BILINEAR)\n",
    "\n",
    "    # 随机亮度/对比度\n",
    "    if random.random() < 0.6:\n",
    "        factor = random.uniform(0.7, 1.4)\n",
    "        img = ImageEnhance.Brightness(img).enhance(factor)\n",
    "    if random.random() < 0.6:\n",
    "        factor = random.uniform(0.7, 1.4)\n",
    "        img = ImageEnhance.Contrast(img).enhance(factor)\n",
    "\n",
    "    # 轻微高斯模糊（防锐化过拟合）\n",
    "    if random.random() < 0.2:\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.3, 0.8)))\n",
    "\n",
    "    # 随机擦除（CoarseDropout 模拟）\n",
    "    if random.random() < 0.3:\n",
    "        arr = np.array(img)\n",
    "        h, w = arr.shape\n",
    "        for _ in range(random.randint(1, 6)):\n",
    "            x = random.randint(0, w-4)\n",
    "            y = random.randint(0, h-4)\n",
    "            arr[y:y+random.randint(1,4), x:x+random.randint(1,4)] = 0\n",
    "        img = Image.fromarray(arr)\n",
    "\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T18:12:39.573844Z",
     "start_time": "2025-11-06T18:12:39.571043Z"
    }
   },
   "id": "d1546991b1e37cb6",
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def im2col(input_data, kernel_h, kernel_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "    将输入转换为列矩阵，每个 filter 大小的块展平为一行。\n",
    "    \n",
    "    input_data: shape (N, C, H, W)\n",
    "    返回: shape (N * out_h * out_w, C * kernel_h * kernel_w)\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "\n",
    "    out_h = (H + 2 * pad - kernel_h) // stride + 1\n",
    "    out_w = (W + 2 * pad - kernel_w) // stride + 1\n",
    "\n",
    "    # 填充\n",
    "    img = np.pad(input_data, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "\n",
    "    # 初始化 col 矩阵\n",
    "    col = np.zeros((N, C, kernel_h, kernel_w, out_h, out_w))\n",
    "\n",
    "    # 利用步进提取每个窗口\n",
    "    # 这一步很有趣，虽然说是每一次把filter对应的img data 铺平成一行，但是这边不是这样做的\n",
    "    for i in range(kernel_h):\n",
    "        i_max = i + stride * out_h\n",
    "        for j in range(kernel_w):\n",
    "            j_max = j + stride * out_w\n",
    "            col[:, :, i, j, :, :] = img[:, :, i:i_max:stride, j:j_max:stride]\n",
    "        \n",
    "\n",
    "    # 转置 + reshape：把 (N, out_h, out_w, C, K_h, K_w) -> (N*out_h*out_w, C*K_h*K_w)\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)\n",
    "    return col\n",
    "\n",
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    col :\n",
    "    input_shape : 输入数据的形状（例：(10, 1, 28, 28)）\n",
    "    filter_h :\n",
    "    filter_w\n",
    "    stride\n",
    "    pad\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T18:12:39.577049Z",
     "start_time": "2025-11-06T18:12:39.574219Z"
    }
   },
   "id": "ad50e73ec2a61f26",
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, K, b, stride = 1, pad = 0):\n",
    "        self.K = K\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 中间数据（backward时使用）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_K = None\n",
    "        \n",
    "        # 权重和偏置参数的梯度\n",
    "        self.dK = None\n",
    "        self.db = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        fn, c, kh, kw = self.K.shape\n",
    "        N,C,H,W = x.shape\n",
    "        out_h = (H + 2* self.pad -kh)//self.stride + 1\n",
    "        out_w = (W + 2* self.pad -kw)//self.stride + 1\n",
    "        col = im2col(x,kh, kw, self.stride, self.pad)\n",
    "        col_K = self.K.reshape(fn, -1).T\n",
    "        out = col@col_K + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_K = col_K\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        FN, C, FH, FW = self.K.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dK = np.dot(self.col.T, dout)\n",
    "        self.dK = self.dK.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = dout @ self.col_K.T\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T18:12:39.580590Z",
     "start_time": "2025-11-06T18:12:39.577949Z"
    }
   },
   "id": "cf0c727f13707610",
   "execution_count": 187
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T18:12:39.583593Z",
     "start_time": "2025-11-06T18:12:39.581109Z"
    }
   },
   "id": "11457bf67747b870",
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class simpleConvNet:\n",
    "    # conv -> relu -> pool ->conv->relu->pool->full->relu->full\n",
    "        def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_nums':[8, 16], 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=64, output_size=5, weight_init_std=0.01):\n",
    "            filter_nums = conv_param['filter_nums']\n",
    "            filter_size = conv_param['filter_size']\n",
    "            filter_pad = conv_param['pad']\n",
    "            filter_stride = conv_param['stride']\n",
    "            input_size = input_dim[1]\n",
    "    \n",
    "            # 初始化权重\n",
    "            self.params = {}\n",
    "            self.params['K1'] = np.random.randn(filter_nums[0], input_dim[0], filter_size, filter_size).astype(np.float32) * np.sqrt(2.0 / (filter_size * filter_size * input_dim[0]))\n",
    "            \n",
    "            self.params['b1'] = np.zeros(filter_nums[0])\n",
    "            self.params['K2'] = np.random.randn(filter_nums[1], filter_nums[0], filter_size, filter_size).astype(np.float32) * np.sqrt(2.0 / (filter_size * filter_size * filter_nums[0]))\n",
    "            self.params['b2'] = np.zeros(filter_nums[1])\n",
    "            \n",
    "            s1 = input_size - filter_size + 1\n",
    "            s1p = s1 // 2\n",
    "            s2 = s1p - filter_size + 1\n",
    "            s2p = s2 // 2\n",
    "            self.flat_dim = s2p * s2p * filter_nums[1]\n",
    "            \n",
    "            self.params['W1'] = np.random.randn(self.flat_dim, hidden_size).astype(np.float32) * np.sqrt(2.0 / self.flat_dim)\n",
    "            self.params['b3'] = np.zeros((hidden_size,), dtype=np.float32)\n",
    "            self.params['W2'] = np.random.randn(hidden_size, output_size).astype(np.float32) * np.sqrt(2.0 / hidden_size)\n",
    "            self.params['b4'] = np.zeros((output_size,), dtype=np.float32)\n",
    "    \n",
    "            # 生成层\n",
    "            self.layers = OrderedDict()\n",
    "            self.layers['Conv1'] = Convolution(self.params['K1'], self.params['b1'],\n",
    "                                               filter_stride, filter_pad)\n",
    "            self.layers['Relu1'] = Relu()\n",
    "            self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "            self.layers['Conv2'] = Convolution(self.params['K2'], self.params['b2'], filter_stride, filter_pad)\n",
    "            self.layers['Relu2'] = Relu()\n",
    "            self.layers['Pool2'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "            self.layers['Affine1'] = Affine(self.params['W1'], self.params['b3'])\n",
    "            self.layers['Relu3'] = Relu()\n",
    "            self.layers['Affine2'] = Affine(self.params['W2'], self.params['b4'])\n",
    "    \n",
    "            self.last_layer = SoftmaxWithLoss()\n",
    "    \n",
    "        def predict(self, x):\n",
    "            for layer in self.layers.values():\n",
    "                x = layer.forward(x)\n",
    "    \n",
    "            return x\n",
    "    \n",
    "        def loss(self, x, t):\n",
    "            \"\"\"求损失函数\n",
    "            \"\"\"\n",
    "            y = self.predict(x)\n",
    "            return y, self.last_layer.forward(y, t)\n",
    "    \n",
    "        def accuracy(self, x, t, batch_size=100):\n",
    "            if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "            \n",
    "            acc = 0.0\n",
    "            \n",
    "            for i in range(int(x.shape[0] / batch_size)):\n",
    "                tx = x[i*batch_size:(i+1)*batch_size]\n",
    "                tt = t[i*batch_size:(i+1)*batch_size]\n",
    "                y = self.predict(tx)\n",
    "                y = np.argmax(y, axis=1)\n",
    "                acc += np.sum(y == tt) \n",
    "            \n",
    "            return acc / x.shape[0]\n",
    "    \n",
    "        def gradient(self, x, t):\n",
    "            \"\"\"求梯度（误差反向传播法）\n",
    "    \n",
    "            Parameters\n",
    "            ----------\n",
    "            x : 输入数据\n",
    "            t : 教师标签\n",
    "    \n",
    "            Returns\n",
    "            -------\n",
    "            具有各层的梯度的字典变量\n",
    "                grads['W1']、grads['W2']、...是各层的权重\n",
    "                grads['b1']、grads['b2']、...是各层的偏置\n",
    "            \"\"\"\n",
    "    \n",
    "            # backward\n",
    "            dout = 1\n",
    "            dout = self.last_layer.backward(dout)\n",
    "    \n",
    "            layers = list(self.layers.values())\n",
    "            layers.reverse()\n",
    "            for layer in layers:\n",
    "                dout = layer.backward(dout)\n",
    "    \n",
    "            # 设定\n",
    "            grads = {}\n",
    "            grads['K1'], grads['b1'] = self.layers['Conv1'].dK, self.layers['Conv1'].db\n",
    "            grads['K2'], grads['b2'] = self.layers['Conv2'].dK, self.layers['Conv2'].db\n",
    "            grads['W1'], grads['b3'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "            grads['W2'], grads['b4'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "    \n",
    "            return grads\n",
    "            \n",
    "        def save_params(self, file_name=\"params.pkl\"):\n",
    "            params = {}\n",
    "            for key, val in self.params.items():\n",
    "                params[key] = val\n",
    "            with open(file_name, 'wb') as f:\n",
    "                pickle.dump(params, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T18:12:39.589328Z",
     "start_time": "2025-11-06T18:12:39.584401Z"
    }
   },
   "id": "57d196651ae27e11",
   "execution_count": 189
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W =W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # 权重和偏置参数的导数\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 对应张量\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # 还原输入数据的形状（对应张量）\n",
    "        return dx\n",
    "    \n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None # softmax的输出\n",
    "        self.t = None # 监督数据\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss= cross_entropy_loss(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # 监督数据是one-hot-vector的情况\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \n",
    "        return dx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T18:12:39.592412Z",
     "start_time": "2025-11-06T18:12:39.589774Z"
    }
   },
   "id": "39b77e4e1ffb39df",
   "execution_count": 190
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 一些工具\n",
    "# === Simple dataset loader for folder structure ===\n",
    "IMG_SIZE = 100\n",
    "\n",
    "def accuracy(logits, y):\n",
    "    preds = np.argmax(softmax(logits), axis=1)\n",
    "    return float(np.mean(preds == y))\n",
    "\n",
    "def list_images(root: str) -> Tuple[list, list]:\n",
    "    classes = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))])\n",
    "    items = []\n",
    "    for ci, cname in enumerate(classes):\n",
    "        cdir = os.path.join(root, cname)\n",
    "        for fn in os.listdir(cdir):\n",
    "            if fn.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                items.append((os.path.join(cdir, fn), ci))\n",
    "    return items, classes\n",
    "\n",
    "def load_batch(paths_labels, start, end, img_size=IMG_SIZE, augment=False):\n",
    "    batch = paths_labels[start:end]\n",
    "    N = len(batch)\n",
    "    X = np.zeros((N, 1,img_size, img_size), dtype=np.float32)\n",
    "    y = np.zeros((N,), dtype=np.int64)\n",
    "    for i, (p, lab) in enumerate(batch):\n",
    "        img = Image.open(p).convert('L')  # grayscale\n",
    "        if augment:\n",
    "           # img = augment_pil(img, img_size)\n",
    "            # 1. 水平翻转\n",
    "            if random.random() < 0.5:\n",
    "                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "            # 2. 旋转 (-15° ~ +15°)\n",
    "            if random.random() < 0.4:\n",
    "                angle = random.uniform(-15, 15)\n",
    "                img = img.rotate(angle, resample=Image.BILINEAR, fillcolor=0)\n",
    "\n",
    "            # 3. 缩放 (0.9x ~ 1.1x)\n",
    "            if random.random() < 0.4:\n",
    "                scale = random.uniform(0.9, 1.1)\n",
    "                w, h = img.size\n",
    "                new_w, new_h = int(w * scale), int(h * scale)\n",
    "                img = img.resize((new_w, new_h), Image.BILINEAR)\n",
    "                # 裁剪或填充回原尺寸（这里用 center crop + pad）\n",
    "                if scale > 1.0:\n",
    "                    # zoom in: center crop\n",
    "                    left = (new_w - w) // 2\n",
    "                    top = (new_h - h) // 2\n",
    "                    img = img.crop((left, top, left + w, top + h))\n",
    "                else:\n",
    "                    # zoom out: pad with black\n",
    "                    img = ImageOps.pad(img, (w, h), color=0, centering=(0.5, 0.5))\n",
    "\n",
    "            # 4. 平移 (-10% ~ +10% of size)\n",
    "            if random.random() < 0.4:\n",
    "                w, h = img.size\n",
    "                tx = random.uniform(-0.1, 0.1) * w\n",
    "                ty = random.uniform(-0.1, 0.1) * h\n",
    "                img = img.transform(\n",
    "                    (w, h),\n",
    "                    Image.AFFINE,\n",
    "                    (1, 0, tx, 0, 1, ty),\n",
    "                    resample=Image.BILINEAR,\n",
    "                    fillcolor=0\n",
    "                )\n",
    "\n",
    "            # 5. 剪切 (shear, -10° ~ +10°)\n",
    "            if random.random() < 0.3:\n",
    "                shear_angle = random.uniform(-10, 10)  # degrees\n",
    "                shear_factor = np.tan(np.radians(shear_angle))\n",
    "                w, h = img.size\n",
    "                img = img.transform(\n",
    "                    (w, h),\n",
    "                    Image.AFFINE,\n",
    "                    (1, shear_factor, 0, 0, 1, 0),\n",
    "                    resample=Image.BILINEAR,\n",
    "                    fillcolor=0\n",
    "                )\n",
    "                \n",
    "        img = img.resize((img_size, img_size), Image.BILINEAR)\n",
    "        X[i] = np.expand_dims(np.asarray(img, dtype=np.float32) / 255.0, axis=0)\n",
    "        y[i] = lab\n",
    "    return X, y\n",
    "\n",
    "def state_dict(model):\n",
    "    \"\"\"\n",
    "    Collect all top-level numpy array attributes from the model.\n",
    "    Returns a dict: {name: np.ndarray}\n",
    "    \"\"\"\n",
    "    sd = {}\n",
    "    for name, val in vars(model).items():\n",
    "        if isinstance(val, np.ndarray):\n",
    "            sd[name] = val\n",
    "    return sd\n",
    "\n",
    "def load_state_dict(model, state, strict=True):\n",
    "    \"\"\"\n",
    "    Load arrays from `state` (a dict of name->ndarray) into model attributes.\n",
    "    If strict=True, raises on missing keys or shape mismatch.\n",
    "    Returns a report dict.\n",
    "    \"\"\"\n",
    "    report = {\"loaded\": [], \"missing_in_model\": [], \"missing_in_state\": [], \"shape_mismatch\": []}\n",
    "    model_vars = vars(model)\n",
    "    # apply\n",
    "    for k, arr in state.items():\n",
    "        if k not in model_vars:\n",
    "            report[\"missing_in_model\"].append(k)\n",
    "            if strict:\n",
    "                raise KeyError(f\"Parameter '{k}' not found in model.\")\n",
    "            continue\n",
    "        if not isinstance(model_vars[k], np.ndarray):\n",
    "            report[\"shape_mismatch\"].append((k, \"not an ndarray on model\"))\n",
    "            if strict:\n",
    "                raise TypeError(f\"Model attribute '{k}' is not an ndarray.\")\n",
    "            continue\n",
    "        if model_vars[k].shape != arr.shape:\n",
    "            report[\"shape_mismatch\"].append((k, (model_vars[k].shape, arr.shape)))\n",
    "            if strict:\n",
    "                raise ValueError(f\"Shape mismatch for '{k}': model {model_vars[k].shape} vs state {arr.shape}\")\n",
    "            # non-strict: still load\n",
    "        setattr(model, k, arr.astype(model_vars[k].dtype, copy=True))\n",
    "        report[\"loaded\"].append(k)\n",
    "    # find params that were expected but not provided\n",
    "    for k, v in model_vars.items():\n",
    "        if isinstance(v, np.ndarray) and k not in state:\n",
    "            report[\"missing_in_state\"].append(k)\n",
    "    return report"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T18:12:39.597530Z",
     "start_time": "2025-11-06T18:12:39.592821Z"
    }
   },
   "id": "887dab96f58b915f",
   "execution_count": 191
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['bird', 'car', 'cat', 'dog', 'person'] (num_classes=5)\n",
      "\n",
      "=== Epoch 1/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1: 100%|███████████| 32/32 [00:04<00:00,  6.75it/s, acc=25.0%, loss=1.679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Train: loss=1.7219, acc=0.258, time=4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 1: 100%|██████████████| 16/16 [00:00<00:00, 17.57it/s, acc=0.0%, loss=1.844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Val  : loss=1.6105, acc=0.272, time=0.9s\n",
      "\n",
      "=== Epoch 2/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 2: 100%|███████████| 32/32 [00:04<00:00,  6.84it/s, acc=25.0%, loss=1.654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 Train: loss=1.5750, acc=0.280, time=4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 2: 100%|█████████████| 16/16 [00:00<00:00, 16.61it/s, acc=50.0%, loss=1.346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 Val  : loss=1.5782, acc=0.308, time=1.0s\n",
      "\n",
      "=== Epoch 3/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 3: 100%|████████████| 32/32 [00:04<00:00,  7.06it/s, acc=0.0%, loss=1.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 Train: loss=1.5394, acc=0.346, time=4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 3: 100%|█████████████| 16/16 [00:00<00:00, 16.65it/s, acc=40.0%, loss=1.591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 Val  : loss=1.5279, acc=0.344, time=1.0s\n",
      "\n",
      "=== Epoch 4/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 4: 100%|███████████| 32/32 [00:04<00:00,  6.79it/s, acc=25.0%, loss=1.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 Train: loss=1.5141, acc=0.348, time=4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 4: 100%|█████████████| 16/16 [00:00<00:00, 16.66it/s, acc=60.0%, loss=1.022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 Val  : loss=1.5401, acc=0.304, time=1.0s\n",
      "\n",
      "=== Epoch 5/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 5: 100%|███████████| 32/32 [00:04<00:00,  6.70it/s, acc=50.0%, loss=1.090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 Train: loss=1.4865, acc=0.360, time=4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 5: 100%|█████████████| 16/16 [00:01<00:00, 15.73it/s, acc=60.0%, loss=1.035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 Val  : loss=1.5451, acc=0.288, time=1.0s\n",
      "\n",
      "=== Epoch 6/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 6: 100%|███████████| 32/32 [00:04<00:00,  7.13it/s, acc=25.0%, loss=1.679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 Train: loss=1.4657, acc=0.430, time=4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 6: 100%|█████████████| 16/16 [00:01<00:00, 14.94it/s, acc=40.0%, loss=1.412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 Val  : loss=1.5092, acc=0.328, time=1.1s\n",
      "\n",
      "=== Epoch 7/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 7: 100%|███████████| 32/32 [00:05<00:00,  6.39it/s, acc=25.0%, loss=1.630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 Train: loss=1.4389, acc=0.378, time=5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 7: 100%|█████████████| 16/16 [00:00<00:00, 16.83it/s, acc=20.0%, loss=1.717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 Val  : loss=1.4989, acc=0.360, time=1.0s\n",
      "\n",
      "=== Epoch 8/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 8: 100%|██████████| 32/32 [00:04<00:00,  7.24it/s, acc=100.0%, loss=1.011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 Train: loss=1.4048, acc=0.440, time=4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 8: 100%|█████████████| 16/16 [00:00<00:00, 16.80it/s, acc=60.0%, loss=0.959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 Val  : loss=1.5638, acc=0.304, time=1.0s\n",
      "\n",
      "=== Epoch 9/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 9: 100%|███████████| 32/32 [00:04<00:00,  6.81it/s, acc=75.0%, loss=0.967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 Train: loss=1.3723, acc=0.458, time=4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 9: 100%|█████████████| 16/16 [00:00<00:00, 16.09it/s, acc=20.0%, loss=1.824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 Val  : loss=1.5531, acc=0.368, time=1.0s\n",
      "\n",
      "=== Epoch 10/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 10: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s, acc=25.0%, loss=1.474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train: loss=1.3630, acc=0.414, time=4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 10: 100%|████████████| 16/16 [00:00<00:00, 16.55it/s, acc=50.0%, loss=1.028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Val  : loss=1.4988, acc=0.344, time=1.0s\n",
      "\n",
      "=== Epoch 11/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 11: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s, acc=50.0%, loss=1.155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Train: loss=1.3585, acc=0.466, time=4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 11: 100%|████████████| 16/16 [00:00<00:00, 16.96it/s, acc=10.0%, loss=1.731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Val  : loss=1.5682, acc=0.332, time=0.9s\n",
      "\n",
      "=== Epoch 12/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 12: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s, acc=25.0%, loss=1.401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Train: loss=1.3365, acc=0.464, time=4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 12: 100%|████████████| 16/16 [00:00<00:00, 17.15it/s, acc=20.0%, loss=2.107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Val  : loss=1.5116, acc=0.388, time=0.9s\n",
      "\n",
      "=== Epoch 13/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 13: 100%|██████████| 32/32 [00:04<00:00,  7.02it/s, acc=75.0%, loss=0.987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Train: loss=1.3085, acc=0.472, time=4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 13: 100%|████████████| 16/16 [00:00<00:00, 16.82it/s, acc=70.0%, loss=0.763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Val  : loss=1.5909, acc=0.312, time=1.0s\n",
      "\n",
      "=== Epoch 14/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 14: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s, acc=75.0%, loss=1.301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Train: loss=1.3452, acc=0.428, time=4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 14: 100%|████████████| 16/16 [00:00<00:00, 17.24it/s, acc=50.0%, loss=1.173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Val  : loss=1.5396, acc=0.404, time=0.9s\n",
      "\n",
      "=== Epoch 15/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 15: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s, acc=75.0%, loss=0.977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Train: loss=1.3361, acc=0.478, time=4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 15: 100%|████████████| 16/16 [00:01<00:00, 15.81it/s, acc=60.0%, loss=0.955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Val  : loss=1.5387, acc=0.372, time=1.0s\n",
      "\n",
      "=== Epoch 16/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 16: 100%|██████████| 32/32 [00:05<00:00,  6.12it/s, acc=25.0%, loss=1.154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Train: loss=1.2892, acc=0.466, time=5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 16: 100%|████████████| 16/16 [00:00<00:00, 16.12it/s, acc=60.0%, loss=0.933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Val  : loss=1.4888, acc=0.396, time=1.0s\n",
      "\n",
      "=== Epoch 17/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 17: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s, acc=50.0%, loss=2.138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Train: loss=1.2703, acc=0.522, time=4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 17: 100%|████████████| 16/16 [00:01<00:00, 15.90it/s, acc=20.0%, loss=1.913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Val  : loss=1.7503, acc=0.268, time=1.0s\n",
      "\n",
      "=== Epoch 18/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 18: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s, acc=50.0%, loss=1.239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Train: loss=1.3028, acc=0.452, time=4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 18: 100%|████████████| 16/16 [00:00<00:00, 16.99it/s, acc=30.0%, loss=1.437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Val  : loss=1.5053, acc=0.332, time=0.9s\n",
      "\n",
      "=== Epoch 19/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 19: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s, acc=25.0%, loss=1.494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Train: loss=1.3053, acc=0.456, time=4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 19: 100%|████████████| 16/16 [00:00<00:00, 16.99it/s, acc=20.0%, loss=1.533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Val  : loss=1.5156, acc=0.396, time=0.9s\n",
      "\n",
      "=== Epoch 20/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 20: 100%|██████████| 32/32 [00:04<00:00,  6.43it/s, acc=25.0%, loss=2.206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Train: loss=1.2752, acc=0.496, time=5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 20: 100%|████████████| 16/16 [00:01<00:00, 15.83it/s, acc=70.0%, loss=0.885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Val  : loss=1.5088, acc=0.424, time=1.0s\n",
      "\n",
      "=== Epoch 21/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 21: 100%|██████████| 32/32 [00:04<00:00,  6.65it/s, acc=50.0%, loss=1.715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Train: loss=1.2671, acc=0.502, time=4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 21: 100%|████████████| 16/16 [00:01<00:00, 15.98it/s, acc=50.0%, loss=1.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Val  : loss=1.5516, acc=0.424, time=1.0s\n",
      "\n",
      "=== Epoch 22/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 22: 100%|██████████| 32/32 [00:04<00:00,  6.56it/s, acc=25.0%, loss=1.448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Train: loss=1.2062, acc=0.512, time=4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 22: 100%|████████████| 16/16 [00:00<00:00, 18.05it/s, acc=40.0%, loss=1.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Val  : loss=1.5356, acc=0.432, time=0.9s\n",
      "\n",
      "=== Epoch 23/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 23: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s, acc=25.0%, loss=1.650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Train: loss=1.2482, acc=0.498, time=4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 23: 100%|████████████| 16/16 [00:00<00:00, 16.35it/s, acc=70.0%, loss=0.858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Val  : loss=1.5882, acc=0.364, time=1.0s\n",
      "\n",
      "=== Epoch 24/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 24: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s, acc=25.0%, loss=2.019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Train: loss=1.1922, acc=0.540, time=4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 24: 100%|████████████| 16/16 [00:00<00:00, 16.11it/s, acc=30.0%, loss=1.398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Val  : loss=1.4947, acc=0.356, time=1.0s\n",
      "\n",
      "=== Epoch 25/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 25: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s, acc=50.0%, loss=1.117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Train: loss=1.2191, acc=0.504, time=4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 25: 100%|████████████| 16/16 [00:01<00:00, 12.48it/s, acc=90.0%, loss=0.489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Val  : loss=1.7424, acc=0.320, time=1.3s\n",
      "\n",
      "=== Epoch 26/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 26: 100%|██████████| 32/32 [00:04<00:00,  6.62it/s, acc=25.0%, loss=1.167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Train: loss=1.2603, acc=0.484, time=4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 26: 100%|████████████| 16/16 [00:01<00:00, 15.88it/s, acc=60.0%, loss=0.901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Val  : loss=1.5994, acc=0.372, time=1.0s\n",
      "\n",
      "=== Epoch 27/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 27: 100%|██████████| 32/32 [00:04<00:00,  7.08it/s, acc=75.0%, loss=0.564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Train: loss=1.1935, acc=0.536, time=4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 27: 100%|████████████| 16/16 [00:01<00:00, 15.94it/s, acc=30.0%, loss=1.619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Val  : loss=1.5117, acc=0.408, time=1.0s\n",
      "\n",
      "=== Epoch 28/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 28: 100%|█████████| 32/32 [00:04<00:00,  6.52it/s, acc=100.0%, loss=0.321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Train: loss=1.2270, acc=0.528, time=4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 28: 100%|████████████| 16/16 [00:01<00:00, 15.51it/s, acc=30.0%, loss=1.579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Val  : loss=1.5844, acc=0.420, time=1.0s\n",
      "\n",
      "=== Epoch 29/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 29: 100%|██████████| 32/32 [00:05<00:00,  6.40it/s, acc=50.0%, loss=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Train: loss=1.1581, acc=0.538, time=5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 29: 100%|████████████| 16/16 [00:01<00:00, 15.98it/s, acc=90.0%, loss=0.583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Val  : loss=1.5796, acc=0.380, time=1.0s\n",
      "\n",
      "=== Epoch 30/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 30: 100%|██████████| 32/32 [00:04<00:00,  6.61it/s, acc=75.0%, loss=0.934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Train: loss=1.1930, acc=0.514, time=4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val 30: 100%|████████████| 16/16 [00:01<00:00, 15.69it/s, acc=30.0%, loss=1.504]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Val  : loss=1.5757, acc=0.376, time=1.0s\n",
      "\n",
      "✅ Training finished in 2.88 minutes.\n",
      "🔚 Final losses — train: 1.1930, val: 1.5757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train():\n",
    "    data_root = 'dataset'\n",
    "    epochs = 30\n",
    "    batch_size = 16\n",
    "    img_size = 100\n",
    "    use_augment = True\n",
    "    lr=0.03\n",
    "    \n",
    "    t0_total = time.time()\n",
    "    \n",
    "    train_items, classes = list_images(os.path.join(data_root, 'train'))\n",
    "    val_items, _ = list_images(os.path.join(data_root, 'val'))\n",
    "    num_classes = len(classes)\n",
    "    print(f'Classes: {classes} (num_classes={num_classes})')\n",
    "    \n",
    "    network = simpleConvNet(input_dim=(1,100,100), \n",
    "                        conv_param = {'filter_nums': [8,16], 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=64, output_size=5, weight_init_std=0.01)\n",
    "    \n",
    "    last_train_loss, last_val_loss = None, None\n",
    "    \n",
    "    # ---- Prepare save path ----\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        print(f\"\\n=== Epoch {ep}/{epochs} ===\")\n",
    "        random.shuffle(train_items)\n",
    "\n",
    "        # ---- Train ----\n",
    "        t0 = time.time()\n",
    "        loss_accum, acc_accum, seen = 0.0, 0.0, 0\n",
    "        pbar = tqdm(range(0, len(train_items), batch_size), desc=f\"Train {ep}\", ncols=80)\n",
    "        for s in pbar:\n",
    "            X, y = load_batch(train_items, s, min(s+batch_size, len(train_items)), img_size, augment=use_augment)\n",
    "            logits,loss = network.loss(X, y)\n",
    "            \n",
    "            grads = network.gradient(X, y)\n",
    "            # adam = Adam(lr=lr)\n",
    "            # adam.update(network.params, grads = grads)\n",
    "            for key in network.params.keys():\n",
    "                network.params[key] -= lr * grads[key] \n",
    "                \n",
    "            \n",
    "            #loss, dlogits = cross_entropy_loss(probs, y)\n",
    "            #model.backward(dlogits, cache)\n",
    "\n",
    "            acc = accuracy(logits, y)\n",
    "            bsz = X.shape[0]\n",
    "            loss_accum += loss * bsz\n",
    "            acc_accum += acc * bsz\n",
    "            seen += bsz\n",
    "            pbar.set_postfix(loss=f\"{loss:.3f}\", acc=f\"{acc*100:.1f}%\")\n",
    "\n",
    "        last_train_loss = loss_accum / max(1, seen)\n",
    "        train_time = time.time() - t0\n",
    "        print(f\"Epoch {ep:02d} Train: loss={last_train_loss:.4f}, acc={acc_accum/seen:.3f}, time={train_time:.1f}s\")\n",
    "\n",
    "        # ---- Val ----\n",
    "        t1 = time.time()\n",
    "        val_loss, val_acc, vseen = 0.0, 0.0, 0\n",
    "        pbar_val = tqdm(range(0, len(val_items), batch_size), desc=f\"Val {ep}\", ncols=80)\n",
    "        for s in pbar_val:\n",
    "            Xv, yv = load_batch(val_items, s, min(s+batch_size, len(val_items)), img_size, augment=False)\n",
    "            # logits, _ = model.forward(Xv)\n",
    "            # probs = softmax(logits)\n",
    "            # l, _ = cross_entropy_loss(probs, yv)\n",
    "            \n",
    "            logits, l = network.loss(Xv, yv)\n",
    "            a = accuracy(logits, yv)\n",
    "            bsz = Xv.shape[0]\n",
    "            val_loss += l * bsz\n",
    "            val_acc += a * bsz\n",
    "            vseen += bsz\n",
    "            pbar_val.set_postfix(loss=f\"{l:.3f}\", acc=f\"{a*100:.1f}%\")\n",
    "\n",
    "        last_val_loss = val_loss / max(1, vseen)\n",
    "        val_time = time.time() - t1\n",
    "        print(f\"Epoch {ep:02d} Val  : loss={last_val_loss:.4f}, acc={val_acc/vseen:.3f}, time={val_time:.1f}s\")\n",
    "\n",
    "    total_time = time.time() - t0_total\n",
    "    print(f\"\\n✅ Training finished in {total_time/60:.2f} minutes.\")\n",
    "    print(f\"🔚 Final losses — train: {last_train_loss:.4f}, val: {last_val_loss:.4f}\")\n",
    "    \n",
    "\n",
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T18:15:32.429911Z",
     "start_time": "2025-11-06T18:12:39.597962Z"
    }
   },
   "id": "7c47a00046c04b11",
   "execution_count": 192
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-06T18:15:32.448554Z",
     "start_time": "2025-11-06T18:15:32.440313Z"
    }
   },
   "id": "2c2be80d7e323cf",
   "execution_count": 192
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
